{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Groupe 9 - Innovation</b>\n",
    ">- D. Jeauneau (Group leader)\n",
    ">- A. Gahn (Assistant)\n",
    ">- M. Pouchan (Quality manager)\n",
    ">- N. Enjalbert\n",
    ">- F. Estermann\n",
    ">- T. Gallou\n",
    ">- M. Lesavourey\n",
    ">- N. Kired\n",
    ">- M. Manson\n",
    "\n",
    "<b>Contributors</b>  \n",
    "> <b>*Authors</b> : All*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "<b>Goal</b>  \n",
    "The goal of this report is to present the work of the \"Innovation\" group during the \"Interpromo 2020\" project proposed by the SID formation from 6th to 20th January 2020. This project was given by the client Sogeclair for Airbus company.\n",
    "\n",
    "<b>Group</b>  \n",
    "Our group is composed of 9 students : two L3, four M1 and three M2. Unlike the 8 other groups we didn't have a defined subject from the start : we had to innovate in order to find an idea not carried out by another group.  \n",
    "\n",
    "The first two days of the project were dedicated to the search for ideas which were presented to the client. After some turnovers the final subject was decided in Thursday 9th afternoon so we had 8 days to achieve our work which is the creation of a chatbot integrated into the group \"Dashboard\". This will allow interactions between the user and the dashboard.  \n",
    "\n",
    "Furthermore we implemented a predictive system allowing to recommend actions on the site. \n",
    "This project has been a real challenge for our group because we had to show creativity and adaptability to create a useful work.  \n",
    "\n",
    "<b>Fonctionality</b>  \n",
    "When the user sends his request to the chatbot (to interact with the dashboard), the chatbot correct it if there is any typos, then parse the request and transform it into logical representation which is interpretable by both the chatbot and the dashboard. This representation is send back to the dashboard which can now respond to the user request. The chatbot also predict the next request of the user and recommand it in the chat. In order to do so a database of an history of interactions/actions on the dashboard is necessary. Since we had no data we had to generate some to train our models.  \n",
    "\n",
    "<b>Differents parts</b>  \n",
    "To understand a new request from a user, we decided to implement our own NER (Named Entity Recognition) model with a BERT neural network (Bidirectional Encoder Representations from Transformers). The first step of the project was to create a corpus of tagged sentences in order to train our model. Differents structures of sentences with differents propositions and a knowledge base permits us to generates almost a new sentence every time.\n",
    "\n",
    "The second step was tho generate the chatbot-user interaction database. Once the database is created, every result of an interaction is transformed into its unique representation that become a state. We have chosen to represent this database as a markov chain were the probability to move from one state to another is encoded in a transition matrix.\n",
    "\n",
    "A site-chatbot interface was needed between the \"Dashboard\" group and our group in order to have automatic communications. This interface necessitated a representation of the information in a json format. Associations between our tags and the differents part of the json was created with all the data transformations. This format was then used by all the parts of the chatbot.\n",
    "\n",
    "\n",
    "At the end of the project we managed to have a functional V0. Unfortunately, due to lack of time, the chatbot could not be integrated into the dahsboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment\n",
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import json\n",
    "from simpletransformers.ner import NERModel\n",
    "from gensim.models import KeyedVectors\n",
    "from strsimpy.jaro_winkler import JaroWinkler\n",
    "from spellchecker import SpellChecker  # pyspellchecker\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data loading\n",
    "\n",
    "##### Loads NER and W2V models \n",
    "source for the NER model : https://ufile.io/ichyycfe (or train it with bert_tagger.ipynb)  \n",
    "source for the W2V model : https://github.com/eyaler/word2vec-slim/blob/master/GoogleNews-vectors-negative300-SLIM.bin.gz  \n",
    "source for df_transitions : markov.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run constants.ipynb\n",
    "%run dictionnaries.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tags = get_all_tags()\n",
    "tagger = NERModel(model_type='bert',\n",
    "                  model_name=data_directory+'bert/current_model/',\n",
    "                  labels=all_tags,\n",
    "                  use_cuda=False)\n",
    "\n",
    "model_w2v = KeyedVectors.load_word2vec_format(pathword2vec, binary=True)\n",
    "voc_stopwords = set(stopwords.words('english'))\n",
    "db = get_DB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transitions = pd.read_csv(bdd_directory+'df_transitions.csv',\n",
    "                             sep='ยง',\n",
    "                             engine='python',\n",
    "                             index_col=0,\n",
    "                             encoding='utf-8')\n",
    "df_transitions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_facts = pd.read_csv(bdd_directory+'df_facts.csv',\n",
    "                       sep='ยง',\n",
    "                       engine='python',\n",
    "                       index_col=0,\n",
    "                       encoding='utf-8')\n",
    "df_facts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run functions.ipynb\n",
    "%run tag_to_filter.v1.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot  \n",
    "The chatbot will be a class Chatbot that contains differents part for differents intents (class Intent), with a classification system (class Classifieur) that permit to choose the best intent in regard to the user request. One of the intents also have a predictor (class Predictor)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intents\n",
    "We create an Intent class. A intent is a function of a chatbot that a user wants to use, there can be multiple differents ones.\n",
    "\n",
    "An Intent has a state (interface_in) that is the information representation (json format) that was send to the chatbot by the dashboard. It also has a interface_out state that is the response of the chatbot to the interface, this response is called by get_interface_out(). A user interact with the chatbot with the interact() method, while the dashboard can synchronise the chatbot with the synchronize() method when the user is not using the chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Intent:\n",
    "    \"\"\" An intent is a function fo a chatbot, there can be multiple one.\n",
    "    This is a mother class\"\"\"\n",
    "\n",
    "    def __init__(self, name: str, state: str = None):\n",
    "        if state is None:\n",
    "            state = json.dumps(init_event(tab=CT_tabs_default))\n",
    "        self.name = name\n",
    "        self.interface_in = state\n",
    "        self.interface_out = None\n",
    "\n",
    "    def synchronize(self, event: str):\n",
    "        \"\"\" Even when there is no intercation with the chatboat, the dashboard\n",
    "        can synchronize it to get information back\"\"\"\n",
    "\n",
    "        self.interface_in = event\n",
    "        self.interface_out = None\n",
    "\n",
    "    def get_interface_in(self) -> str:\n",
    "        \"\"\" get the traduction of the intput from the interface\n",
    "        with the dashboard\"\"\"\n",
    "\n",
    "        return self.interface_in\n",
    "\n",
    "    def get_interface_out(self) -> str:\n",
    "        \"\"\" get the traduction of the output for the interface\n",
    "        with the dashboard\"\"\"\n",
    "\n",
    "        return self.interface_out\n",
    "\n",
    "    def interact(self, sentence: str = None) -> str:\n",
    "        \"\"\" This method is called by the chatbot and must return the sentence\n",
    "        to show in the chat\"\"\"\n",
    "\n",
    "        return \"Please implement this method\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displayer - recommandation intent\n",
    "The main intent of our chatbot is to understand what the user wants to see on the dashboard. The user send a request in the form of a sentence in the chat, this request is corrected if there are typos and the chatbot send the decoded information back to the chatbot-dashboard interface to be interpretated by the dashboard.\n",
    "\n",
    "It also predict the next graphs the user would like to see and ask him if he is interested by that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creation of the class Predictor for the recommandation (prediction of next state with a markov chain)\n",
    "This object contain all the past interactions user-dashboard from where we can predict the next most probable state. Here we choose a random state and predict the next one as an example from a transition matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"filters\": {\"aircraft\": [\"a318\", \"a320\", \"a340-300\", \"a350-900\"], \"category\": [], \"company\": [], \"country\": [\"england\", \"france\", \"germany\", \"italy\", \"spain\"], \"date\": [\"01092017\", \"30092017\"], \"manufacturer\": [\"airbus\"]}, \"tab\": \"general\"}'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Predictor:\n",
    "    \"\"\" This class is used to create the recommandation module\"\"\"\n",
    "\n",
    "    def __init__(self, name: str, transitions: pd.DataFrame):\n",
    "        self.name = name\n",
    "        self.transitions = transitions\n",
    "\n",
    "    def predict(self, event: str) -> str:\n",
    "        \"\"\" give the recommanded state\"\"\"\n",
    "        predict = predict_next_state(event, self.transitions)\n",
    "        return predict\n",
    "\n",
    "    def random_state(self):\n",
    "        \"\"\" give a random state\"\"\"\n",
    "        return np.random.choice(self.transitions.index)\n",
    "\n",
    "\n",
    "markov = Predictor(name='Markov', transitions=df_transitions.dropna())\n",
    "markov.predict(markov.random_state())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### creation of the intent displayer-recommandation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Displayer(Intent):\n",
    "    \"\"\" A displayer is an intent that understand a user sentence and return\n",
    "    to the dashboard by the interface the board to show and a next\n",
    "    recommandation \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 name: str,\n",
    "                 model_tagger: NERModel,\n",
    "                 model_predicteur: Predictor,\n",
    "                 model_w2v: KeyedVectors,\n",
    "                 db: dict = {},\n",
    "                 voc_stopwords: set = set(),\n",
    "                 state: str = None):\n",
    "\n",
    "        super(Displayer, self).__init__(name)\n",
    "        self.tagger = model_tagger\n",
    "        self.predicteur = model_predicteur\n",
    "        self.w2v = model_w2v\n",
    "        self.voc_stopwords = voc_stopwords\n",
    "        self.db = db\n",
    "\n",
    "    def synchronize(self, event: str):\n",
    "        self.interface_in = json_string_to_hash(event)\n",
    "        self.interface_out = self.predicteur.predict(self.interface_in)\n",
    "\n",
    "    def get_tags(self, sentence: str) -> list:\n",
    "        \"\"\" Associate a tag to each word\"\"\"\n",
    "\n",
    "        sentence_corrected = self.auto_correction(sentence)\n",
    "        request = self.tagger.predict([sentence_corrected])[0][0]\n",
    "        print(request, '\\n')\n",
    "        return request\n",
    "\n",
    "    def get_filters(self, sentence: str) -> dict:\n",
    "        \"\"\" create the state to communicate with the dashboard\"\"\"\n",
    "\n",
    "        request = self.get_tags(sentence)\n",
    "        tags_values = extract_tags(request)\n",
    "        filters = tag_to_filters(tags_values)\n",
    "        filters = apply_date(filters)\n",
    "        event = {\n",
    "            CT_tabs: CT_tabs_default,\n",
    "            CT_filt: filters,\n",
    "        }\n",
    "        return event\n",
    "\n",
    "    def get_output_sentence(self, pred_state_hash: str) -> str:\n",
    "        \"\"\" create a sentence from a state \"\"\"\n",
    "\n",
    "        pred_sentence = make_sentence_fom_json(json.loads(pred_state_hash))\n",
    "        return pred_sentence\n",
    "\n",
    "    def interact(self, sentence: str) -> str:\n",
    "        event = self.get_filters(sentence)\n",
    "        event_state = json.dumps(event)\n",
    "        self.synchronize(event_state)\n",
    "\n",
    "        pred_state_hash = self.get_interface_out()\n",
    "        pred_sentence = self.get_output_sentence(pred_state_hash)\n",
    "\n",
    "        res = pred_sentence\n",
    "        return res\n",
    "\n",
    "    def auto_correction(self, sentence: str):\n",
    "        \"\"\" correction for typos before processing \"\"\"\n",
    "\n",
    "        return auto_correction(self.w2v.vocab, db, voc_stopwords, sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make our Displayer-Recommandation intent using our NER model, Markov model, W2V model, and the information contained in the database. The W2V model with the database and some stopwords are used to make the automatic typos correction, while the tagger model is used to understand the request and the markov model to predict the next state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displayer_Recommandation\n",
      "None\n",
      "{\"filters\": {\"aircraft\": [], \"category\": [], \"company\": [], \"country\": [\"england\", \"france\", \"germany\", \"italy\", \"spain\"], \"date\": [\"01092017\", \"30092017\"], \"manufacturer\": [\"airbus\"]}, \"tab\": \"general\"}\n"
     ]
    }
   ],
   "source": [
    "Intent_displayer = Displayer(name='Displayer_Recommandation',\n",
    "                             model_tagger=tagger,\n",
    "                             model_predicteur=markov,\n",
    "                             model_w2v=model_w2v,\n",
    "                             voc_stopwords=voc_stopwords,\n",
    "                             db=db)\n",
    "print(Intent_displayer.name)\n",
    "print(Intent_displayer.get_interface_out())\n",
    "Intent_displayer.synchronize(Intent_displayer.interface_in)\n",
    "print(Intent_displayer.get_interface_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random intent\n",
    "This intent is here just to have multiple ones in order to create an intent classifier in our chatbot. Its purpose is to show differents facts in the airplanes industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Random_info(Intent):\n",
    "    \"\"\" An other intent implemetation which randomly choose a sentences\n",
    "    from a database if called\"\"\"\n",
    "\n",
    "    def __init__(self, name, db={}):\n",
    "        super(Random_info, self).__init__(name)\n",
    "        self.db = db\n",
    "\n",
    "    def interact(self, sentence: str = None) -> str:\n",
    "        output = None\n",
    "        if db:\n",
    "            k = np.random.choice(list(random_bdd.keys()))\n",
    "            output = np.random.choice(list(random_bdd[k][\"sentences\"]))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A woman from Stockholm, Sweden, attempted to smuggle 75 live snakes onto an airplane by placing them in her bra. She also had six lizards under her shorts.\n"
     ]
    }
   ],
   "source": [
    "random_bdd = {}\n",
    "for s in list(df_facts['subject'].unique()):\n",
    "    random_bdd[s] = {}\n",
    "    random_bdd[s]['sentences'] = set(\n",
    "        df_facts.loc[df_facts['subject'] == s, 'facts'].values)\n",
    "\n",
    "Intent_random_info = Random_info(name='Random_Info', db=random_bdd)\n",
    "print(Intent_random_info.interact())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intent classifier\n",
    "Here we create an intent classifier. If the user writes 'fact' in the chatbot, the classifier return 1 and the random_intent will be used, else it return 0 and the diplayer is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "class Classifier:\n",
    "    \"\"\" This classifier let the chatbot choose the best intent when\n",
    "    receiving a user request\"\"\"\n",
    "\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "\n",
    "    def predict(self, sentence: str) -> int:\n",
    "        if sentence.lower() == 'fact':\n",
    "            c = 1\n",
    "        else:\n",
    "            c = 0\n",
    "        return c\n",
    "\n",
    "\n",
    "classifier = Classifier(name='Intent classifieur')\n",
    "print(classifier.predict(sentence=\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': <__main__.Classifier at 0x7f4dabb078d0>,\n",
       " 'intents': {0: <__main__.Displayer at 0x7f4dabad37f0>,\n",
       "  1: <__main__.Random_info at 0x7f4dabae0940>}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intents = {\"classifier\": classifier,\n",
    "           \"intents\": {0: Intent_displayer,\n",
    "                       1: Intent_random_info}\n",
    "           }\n",
    "intents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbot\n",
    "Finally we create the Chatbot class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ChatBot:\n",
    "    \"\"\" The Chatbot\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name, intents: dict):\n",
    "        self.name = name\n",
    "        self.classifier = intents['classifier']\n",
    "        self.intents = intents['intents']\n",
    "        self.active_intent = list(intents.keys())[0]\n",
    "\n",
    "    def classify(self, sentence: str) -> int:\n",
    "        \"\"\" Choose the best intent \"\"\"\n",
    "\n",
    "        self.active_intent = self.classifier.predict(sentence)\n",
    "\n",
    "    def interact(self, sentence: str) -> str:\n",
    "        \"\"\" Call the interact method of the selected intent \n",
    "        and return the sentence generated\"\"\"\n",
    "\n",
    "        self.classify(sentence)\n",
    "        intent = self.intents[self.active_intent]\n",
    "        interaction = intent.interact(sentence)\n",
    "        return interaction\n",
    "\n",
    "    def synchronize(self, event: str):\n",
    "        \"\"\" synchronize all the intents \"\"\"\n",
    "\n",
    "        for intent in self.intents.values():\n",
    "            intent.synchronize(event)\n",
    "\n",
    "    def get_interface_in(self) -> str:\n",
    "        \"\"\" get the traduction of the input from the interface\n",
    "        with the dashboard\"\"\"\n",
    "\n",
    "        return self.intents[self.active_intent].get_interface_in()\n",
    "\n",
    "    def get_interface_out(self) -> str:\n",
    "        \"\"\" get the traduction of the output for the interface\n",
    "        with the dashboard\"\"\"\n",
    "\n",
    "        return self.intents[self.active_intent].get_interface_out()\n",
    "\n",
    "\n",
    "Hubert = ChatBot(name='Chatbot Hubert', intents=intents)\n",
    "Hubert.classify('aertetreb')\n",
    "Hubert.active_intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to features started.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58e2c3ed0744ba690f0c839624484cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ae24d2fac414a42b68a617ab5f38845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[{'Show': 'O'}, {'me': 'O'}, {'the': 'O'}, {'graph': 'STAT_B'}, {'of': 'O'}, {'passengers': 'STUDIED_B'}, {'contentment': 'STUDIED_E'}, {'for': 'O'}, {'Matra': 'MANU_B'}, {'and': 'O'}, {'MATRA': 'MANU_B'}, {'and': 'O'}, {'AIRBUS': 'MANU_B'}, {'in': 'O'}, {'CONGO': 'COUN_B'}, {'from': 'O'}, {'10/1993': 'DATE1_B'}, {'to': 'O'}, {'the': 'O'}, {'end': 'O'}, {'of': 'O'}, {'the': 'O'}, {'year': 'O'}, {'1946': 'DATE2_B'}] \n",
      "\n",
      "IN :\t {\"filters\": {\"aircraft\": [], \"category\": [], \"company\": [], \"country\": [\"congo\"], \"date\": [\"01101993\", \"31121946\"], \"manufacturer\": [\"airbus\", \"matra\"]}, \"tab\": \"general\"} \n",
      "\n",
      "We suggest you the global study from 01-09-2017 to 30-09-2017 for the manufacturer airbus and for the aircrafta350-900 in the countries england, france, germany, italy, spain. If you agree, click on the following link ;) \n",
      "\n",
      "OUT :\t {\"filters\": {\"aircraft\": [\"a350-900\"], \"category\": [], \"company\": [], \"country\": [\"england\", \"france\", \"germany\", \"italy\", \"spain\"], \"date\": [\"01092017\", \"30092017\"], \"manufacturer\": [\"airbus\"]}, \"tab\": \"general\"} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sent = 'Show me the graph of passengrs contentments for Matra  \\\n",
    "    and MATRA and AIRBUS in CONGO from 10/1993 to the end of the year 1946'\n",
    "\n",
    "output_sentence = Hubert.interact(sent)\n",
    "input_interfac = Hubert.get_interface_in()\n",
    "output_interfac = Hubert.get_interface_out()\n",
    "\n",
    "print(\"IN :\\t\", input_interfac, '\\n')\n",
    "print(output_sentence, '\\n')\n",
    "print(\"OUT :\\t\", output_interfac, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next\n",
    "The integration with the dashboard is not complete yet because of rapid changes in the dashboard design and because of the redirection of our subject during the project.\n",
    "\n",
    "If we had more time, we could have created more tags, more training tagged sentences with differents structures for our NER model to catch more meanings from a user. We would have also implement a better recommandation module, with better choosen states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "264.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
